{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "############################################################\r\n",
    "##################### Build the data #######################\r\n",
    "############################################################\r\n",
    "def build_data(video_list, save_path, width_OF=320, log=None, workers=15, flow_method='DeepFlow'):\r\n",
    "    make_path(save_path)\r\n",
    "\r\n",
    "    # Extract Frames\r\n",
    "    extract_frames(video_list, save_path, width_OF, log)\r\n",
    "\r\n",
    "    # Compute DeepFlow\r\n",
    "    compute_DeepFlow(video_list, save_path, log, workers)\r\n",
    "\r\n",
    "    # Compute ROI\r\n",
    "    compute_ROI(video_list, save_path, log, workers, flow_method=flow_method)\r\n",
    "\r\n",
    "\r\n",
    "##################### RGB #######################\r\n",
    "def extract_frames(video_list, save_path, width_OF, log):\r\n",
    "    # Chrono\r\n",
    "    start_time = time.time()\r\n",
    "\r\n",
    "    for idx, video_path in enumerate(video_list):\r\n",
    "\r\n",
    "        video_name = os.path.basename(video_path)\r\n",
    "        progress_bar(idx, len(video_list),\r\n",
    "                     'Frame extraction - %s' % (video_name))\r\n",
    "\r\n",
    "        path_data_video = os.path.join(save_path, video_name.split('.')[0])\r\n",
    "        make_path(path_data_video)\r\n",
    "        path_RGB = os.path.join(path_data_video, 'RGB')\r\n",
    "        make_path(path_RGB)\r\n",
    "\r\n",
    "        # Load Video\r\n",
    "        cap = cv2.VideoCapture(video_path)\r\n",
    "        length_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\r\n",
    "        frame_number = 0\r\n",
    "\r\n",
    "        # Check if video uploaded\r\n",
    "        if not cap.isOpened():\r\n",
    "            sys.exit(\"Unable to open the video, check the path.\\n\")\r\n",
    "\r\n",
    "        while frame_number < length_video:\r\n",
    "            # Load video\r\n",
    "            _, rgb = cap.read()\r\n",
    "\r\n",
    "            # Check if load Properly\r\n",
    "            if _ == 1:\r\n",
    "                # Resizing and Save\r\n",
    "                rgb = cv2.resize(\r\n",
    "                    rgb, (width_OF, rgb.shape[0] * width_OF // rgb.shape[1]))\r\n",
    "                cv2.imwrite(os.path.join(path_RGB, '%08d.png' %\r\n",
    "                                         frame_number), rgb)\r\n",
    "                frame_number += 1\r\n",
    "        cap.release()\r\n",
    "\r\n",
    "    progress_bar(idx+1, len(video_list), 'Frame extraction completed in %d s' %\r\n",
    "                 (time.time() - start_time), 1, log=log)\r\n",
    "\r\n",
    "##################### Deep Flow #######################\r\n",
    "\r\n",
    "\r\n",
    "def compute_DeepFlow(video_list, save_path, log, workers):\r\n",
    "    start_time = time.time()\r\n",
    "    DeepFlow_pool = ActivePool()\r\n",
    "\r\n",
    "    for idx, video_path in enumerate(video_list):\r\n",
    "\r\n",
    "        video_name = os.path.basename(video_path).split('.')[0]\r\n",
    "        path_data_video = os.path.join(save_path, video_name)\r\n",
    "\r\n",
    "        # Split the calculation in severals process\r\n",
    "        while threading.activeCount() > workers:\r\n",
    "            progress_bar(idx + 1 - threading.activeCount(),\r\n",
    "                         len(video_list), 'DeepFlow computation')\r\n",
    "            time.sleep(0.1)\r\n",
    "\r\n",
    "        if threading.activeCount() <= workers:\r\n",
    "            job = threading.Thread(target=compute_DeepFlow_video, name=idx, args=(DeepFlow_pool,\r\n",
    "                                                                                  os.path.join(\r\n",
    "                                                                                      path_data_video, 'RGB'),\r\n",
    "                                                                                  os.path.join(path_data_video, 'DeepFlow')))\r\n",
    "            job.daemon = True\r\n",
    "            job.start()\r\n",
    "\r\n",
    "    while threading.activeCount() > 1:\r\n",
    "        progress_bar(idx + 1 - threading.activeCount(),\r\n",
    "                     len(video_list), 'DeepFlow computation')\r\n",
    "        time.sleep(0.1)\r\n",
    "\r\n",
    "    progress_bar(idx + 1, len(video_list), 'DeepFlow computation done in %d s' %\r\n",
    "                 (time.time() - start_time), 1, log=log)\r\n",
    "\r\n",
    "\r\n",
    "def compute_DeepFlow_video(pool, path_RGB, path_Flow):\r\n",
    "    name = threading.current_thread().name\r\n",
    "    pool.makeActive(name)\r\n",
    "    os.system('python deep_flow.py -i %s -o %s' % (path_RGB, path_Flow))\r\n",
    "    pool.makeInactive(name)\r\n",
    "\r\n",
    "\r\n",
    "##################### ROI #######################\r\n",
    "def compute_ROI(video_list, save_path, log, workers, flow_method='DeepFlow'):\r\n",
    "    start_time = time.time()\r\n",
    "    ROI_pool = ActivePool()\r\n",
    "\r\n",
    "    for idx, video_path in enumerate(video_list):\r\n",
    "\r\n",
    "        video_name = os.path.basename(video_path).split('.')[0]\r\n",
    "        path_data_video = os.path.join(save_path, video_name)\r\n",
    "\r\n",
    "        # Split the calculation in severals process\r\n",
    "        while threading.activeCount() > workers:\r\n",
    "            progress_bar(idx + 1 - threading.activeCount(),\r\n",
    "                         len(video_list), 'ROI computation for %s' % (flow_method))\r\n",
    "            time.sleep(0.1)\r\n",
    "\r\n",
    "        if threading.activeCount() <= workers:\r\n",
    "            job = threading.Thread(target=compute_roi_video, name=idx, args=(ROI_pool,\r\n",
    "                                                                             path_data_video,\r\n",
    "                                                                             flow_method))\r\n",
    "            job.daemon = True\r\n",
    "            job.start()\r\n",
    "\r\n",
    "    while threading.activeCount() > 1:\r\n",
    "        progress_bar(idx + 1 - threading.activeCount(),\r\n",
    "                     len(video_list), 'ROI computation for %s' % (flow_method))\r\n",
    "        time.sleep(0.1)\r\n",
    "\r\n",
    "    join_values_flow(video_list, 'values_flow_%s' % flow_method)\r\n",
    "    progress_bar(len(video_list), len(video_list), 'ROI computation for %s completed in %d s' % (\r\n",
    "        flow_method, int(time.time() - start_time)), 1, log=log)\r\n",
    "\r\n",
    "\r\n",
    "def compute_roi_video(pool, path_data_video, flow_method):\r\n",
    "    name = threading.current_thread().name\r\n",
    "    pool.makeActive(name)\r\n",
    "    os.system('python roi_flow.py -v %s -m %s' %\r\n",
    "              (path_data_video, flow_method))\r\n",
    "    pool.makeInactive(name)\r\n",
    "\r\n",
    "\r\n",
    "def join_values_flow(video_list, name_values, save_path):\r\n",
    "    values_flow = []\r\n",
    "    for video in video_list:\r\n",
    "        video_name = os.path.basename(video_path).split('.')[0]\r\n",
    "        path_data_video = os.path.join(save_path, video_name)\r\n",
    "        values_flow_video = np.load(os.path.join(\r\n",
    "            path_data_video, '%s.npy' % name_values))\r\n",
    "        values_flow.extend(values_flow_video)\r\n",
    "    np.save(os.path.join(save_path, name_values), values_flow)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "########################  Flatten Features  ##############################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "def flatten_features(x):\r\n",
    "    size = x.size()[1:]  # all dimensions except the batch dimension\r\n",
    "    num_features = 1\r\n",
    "    for s in size:\r\n",
    "        num_features *= s\r\n",
    "    return num_features\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "####################### Twin RGB OptFlow ##############################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "class NetTwin(nn.Module):\r\n",
    "    def __init__(self, size_data, n_classes):\r\n",
    "        super(NetTwin, self).__init__()\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### First ######\r\n",
    "        ####################\r\n",
    "        self.conv1_RGB = nn.Conv3d(\r\n",
    "            3, 30, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool1_RGB = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        self.conv1_Flow = nn.Conv3d(\r\n",
    "            2, 30, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool1_Flow = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        #####################\r\n",
    "        ####### Second ######\r\n",
    "        #####################\r\n",
    "        self.conv2_RGB = nn.Conv3d(\r\n",
    "            30, 60, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool2_RGB = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        self.conv2_Flow = nn.Conv3d(\r\n",
    "            30, 60, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool2_Flow = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Third ######\r\n",
    "        ####################\r\n",
    "        self.conv3_RGB = nn.Conv3d(\r\n",
    "            60, 80, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool3_RGB = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        self.conv3_Flow = nn.Conv3d(\r\n",
    "            60, 80, (3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
    "        self.pool3_Flow = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        #####################\r\n",
    "        ####### Fusion ######\r\n",
    "        #####################\r\n",
    "        self.linear_RGB = nn.Linear(\r\n",
    "            80*size_data[0]*size_data[1]*size_data[2], 500)\r\n",
    "        self.linear_Flow = nn.Linear(\r\n",
    "            80*size_data[0]*size_data[1]*size_data[2], 500)\r\n",
    "\r\n",
    "        self.linear = nn.Bilinear(500, 500, n_classes)\r\n",
    "        self.final = nn.Softmax(1)\r\n",
    "\r\n",
    "    def forward(self, rgb, flowe):\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### First ######\r\n",
    "        ####################\r\n",
    "        rgb = self.pool1_RGB(F.relu(self.conv1_RGB(rgb)))\r\n",
    "        flow = self.pool1_Flow(F.relu(self.conv1_Flow(flow)))\r\n",
    "\r\n",
    "        #####################\r\n",
    "        ####### Second ######\r\n",
    "        #####################\r\n",
    "        rgb = self.pool2_RGB(F.relu(self.conv2_RGB(rgb)))\r\n",
    "        flow = self.pool2_Flow(F.relu(self.conv2_Flow(flow)))\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Third ######\r\n",
    "        ####################\r\n",
    "        rgb = self.pool3_RGB(F.relu(self.conv3_RGB(rgb)))\r\n",
    "        flow = self.pool3_Flow(F.relu(self.conv3_Flow(flow)))\r\n",
    "\r\n",
    "        #####################\r\n",
    "        ####### Fusion ######\r\n",
    "        #####################\r\n",
    "        rgb = rgb.view(-1, flatten_features(rgb))\r\n",
    "        flow = flow.view(-1, flatten_features(flow))\r\n",
    "\r\n",
    "        rgb = F.relu(self.linear_RGB(rgb))\r\n",
    "        flow = F.relu(self.linear_Flow(flow))\r\n",
    "\r\n",
    "        data = self.linear(rgb, flow)\r\n",
    "        label = self.final(data)\r\n",
    "\r\n",
    "        return label\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "#############################  One Branch ################################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "class NetSimpleBranch(nn.Module):\r\n",
    "    def __init__(self, size_data, n_classes, channels=3):\r\n",
    "        super(NetSimpleBranch, self).__init__()\r\n",
    "\r\n",
    "        self.channels = channels\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### First ######\r\n",
    "        ####################\r\n",
    "        self.conv1 = nn.Conv3d(channels, 30, (3, 3, 3), stride=(\r\n",
    "            1, 1, 1), padding=(1, 1, 1))  # dilaion=(0,0,0) (depth, height, width)\r\n",
    "        self.pool1 = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ###### Second ######\r\n",
    "        ####################\r\n",
    "        self.conv2 = nn.Conv3d(30, 60, (3, 3, 3), stride=(1, 1, 1), padding=(\r\n",
    "            1, 1, 1))  # dilaion=(0,0,0) (depth, height, width)\r\n",
    "        self.pool2 = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Third ######\r\n",
    "        ####################\r\n",
    "        self.conv3 = nn.Conv3d(60, 80, (3, 3, 3), stride=(1, 1, 1), padding=(\r\n",
    "            1, 1, 1))  # dilaion=(0,0,0) (depth, height, width)\r\n",
    "        self.pool3 = nn.MaxPool3d((2, 2, 2), stride=(2, 2, 2))\r\n",
    "        size_data //= 2\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Last #######\r\n",
    "        ####################\r\n",
    "        self.linear1 = nn.Linear(\r\n",
    "            80*size_data[0]*size_data[1]*size_data[2], 500)  # 144000, 216000\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "\r\n",
    "        # Fusion\r\n",
    "        self.linear2 = nn.Linear(500, n_classes)\r\n",
    "        self.final = nn.Softmax(1)\r\n",
    "\r\n",
    "    def forward(self, rgb, flow):\r\n",
    "        if self.channels == 2:\r\n",
    "            data = flow\r\n",
    "        else:\r\n",
    "            data = rgb\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### First ######\r\n",
    "        ####################\r\n",
    "        # data = self.pool1(F.relu(self.drop1(self.conv1(data))))\r\n",
    "        data = self.pool1(F.relu(self.conv1(data)))\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ###### Second ######\r\n",
    "        ####################\r\n",
    "        data = self.pool2(F.relu(self.conv2(data)))\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Third ######\r\n",
    "        ####################\r\n",
    "        data = self.pool3(F.relu(self.conv3(data)))\r\n",
    "\r\n",
    "        ####################\r\n",
    "        ####### Last #######\r\n",
    "        ####################\r\n",
    "        data = data.view(-1, flatten_features(data))\r\n",
    "        data = self.relu(self.linear1(data))\r\n",
    "\r\n",
    "        data = self.linear2(data)\r\n",
    "        label = self.final(data)\r\n",
    "\r\n",
    "        return label\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "#########################################################################\r\n",
    "###################### Reset Pytorch Session ############################\r\n",
    "#########################################################################\r\n",
    "\r\n",
    "\r\n",
    "def reset_training(seed):\r\n",
    "    gc.collect()\r\n",
    "    random.seed(seed)\r\n",
    "    np.random.seed(seed)\r\n",
    "    torch.manual_seed(seed)\r\n",
    "\r\n",
    "#################################################################\r\n",
    "###################### Model variables ##########################\r\n",
    "#################################################################\r\n",
    "\r\n",
    "\r\n",
    "class my_variables():\r\n",
    "    def __init__(self, model_type='Twin', batch_size=10, augmentation=True, nesterov=True, decay=0.005, epochs=500, lr=0.001, momentum=0.5, flow_method='DeepFlow', norm_method='NORMAL', size_data=[100, 120, 120], cuda=True):\r\n",
    "\r\n",
    "        self.model_type = model_type\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.nesterov = nesterov\r\n",
    "        self.decay = decay\r\n",
    "        self.lr = lr\r\n",
    "        self.momentum = momentum\r\n",
    "        self.flow_method = flow_method\r\n",
    "        self.norm_method = norm_method\r\n",
    "        self.size_data = np.array(size_data)\r\n",
    "        self.model_name = 'pytorch_%s_%s_bs_%s_aug_%d_nest_%d_decay_%s_lr_%s_m_%s_OF_%s_%s_sizeinput_%s_' % (datetime.datetime.now().strftime(\r\n",
    "            \"%d-%m-%Y_%H-%M\"), self.model_type, self.batch_size, self.augmentation, self.nesterov, self.decay, self.lr, self.momentum, self.flow_method, self.norm_method, str(self.size_data))\r\n",
    "        self.load = False\r\n",
    "\r\n",
    "        self.epochs = epochs\r\n",
    "        self.path_fig_model = os.path.join('Figures', self.model_name)\r\n",
    "        make_path(self.path_fig_model)\r\n",
    "\r\n",
    "        if cuda:  # Use gpu\r\n",
    "            self.dtype = torch.cuda.FloatTensor\r\n",
    "        else:\r\n",
    "            self.dtype = torch.FloatTensor\r\n",
    "\r\n",
    "        self.log = setup_logger('model_log', os.path.join(\r\n",
    "            self.path_fig_model, 'log_%s.log' % datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M\")))\r\n",
    "\r\n",
    "    def state_dict(self):\r\n",
    "        dict = self.__dict__.copy()\r\n",
    "        del dict['log']\r\n",
    "        return dict\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "############################ Dataset Class ###############################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "class My_dataset(Dataset):\r\n",
    "    def __init__(self, dataset_list, size_data, augmentation=0, norm_method=norm_method, flow_method=flow_method):\r\n",
    "        self.dataset_list = dataset_list\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.norm_method = norm_method\r\n",
    "        self.flow_method = flow_method\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.dataset_list)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        rgb, flow, label = get_annotation_data(\r\n",
    "            self.dataset_list[idx], self.size_data, augmentation=self.augmentation, norm_method=self.norm_method, flow_method=self.flow_method)\r\n",
    "        sample = {'rgb': torch.FloatTensor(\r\n",
    "            rgb), 'flow': torch.FloatTensor(flow), 'label': label}\r\n",
    "        return sample\r\n",
    "\r\n",
    "#######################################################################\r\n",
    "############################ Make model ###############################\r\n",
    "#######################################################################\r\n",
    "\r\n",
    "\r\n",
    "def make_the_model(video_list):\r\n",
    "\r\n",
    "    #### Same seed #####\r\n",
    "    reset_training(param.seed)\r\n",
    "\r\n",
    "    ##### Get all the annotations in random order #####\r\n",
    "    annotations_list, negative_list = get_annotations_list(video_list)\r\n",
    "\r\n",
    "    ##### Build Train, Validation and Test set #####\r\n",
    "    train_list, validation_list, test_list = build_lists_set(\r\n",
    "        annotations_list, negative_list)\r\n",
    "\r\n",
    "    # Variables\r\n",
    "    lr = 0.01\r\n",
    "\r\n",
    "    compute_normalization_values(os.path.join(\r\n",
    "        param.path_data, 'values_flow_%s.npy' % 'DeepFlow'))\r\n",
    "\r\n",
    "    args = my_variables()\r\n",
    "\r\n",
    "    ##################\r\n",
    "    ## Architecture ##\r\n",
    "    ##################\r\n",
    "    model = make_architecture(args)\r\n",
    "\r\n",
    "    ######################\r\n",
    "    ## Data preparation ##\r\n",
    "    ######################\r\n",
    "    ##### Build Dataset class and Data Loader #####\r\n",
    "    train_set = My_dataset(train_list, augmentation=args.augmentation, norm_method=args.norm_method,\r\n",
    "                           flow_method=args.flow_method, data_types=args.model_type, fps=args.fps, size_data=args.size_data)\r\n",
    "    validation_set = My_dataset(validation_list, norm_method=args.norm_method, flow_method=args.flow_method,\r\n",
    "                                data_types=args.model_type, fps=args.fps, size_data=args.size_data)\r\n",
    "    test_set = My_dataset(test_list, norm_method=args.norm_method, flow_method=args.flow_method,\r\n",
    "                          data_types=args.model_type, fps=args.fps, size_data=args.size_data)\r\n",
    "\r\n",
    "    ## Loaders of the Datasets\r\n",
    "    train_loader = DataLoader(\r\n",
    "        train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.workers)\r\n",
    "    validation_loader = DataLoader(\r\n",
    "        validation_set, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\r\n",
    "    test_loader = DataLoader(\r\n",
    "        test_set, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\r\n",
    "\r\n",
    "    ######################\r\n",
    "    ## Training process ##\r\n",
    "    ######################\r\n",
    "    train_model(model, args, train_loader, validation_loader)\r\n",
    "    args.load = True\r\n",
    "\r\n",
    "    ## Load best model\r\n",
    "    model = make_architecture(args)\r\n",
    "\r\n",
    "    ##################\r\n",
    "    ## Test process ##\r\n",
    "    ##################\r\n",
    "    test_model(model, args, test_loader, param.list_of_moves)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'norm_method' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c20996821cc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mMy_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflow_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c20996821cc7>\u001b[0m in \u001b[0;36mMy_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMy_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflow_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmentation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'norm_method' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###############################################################################\r\n",
    "########################### Flow Normalization ################################\r\n",
    "###############################################################################\r\n",
    "# Get Normalization value #\r\n",
    "def compute_normalization_values(path_data, list_videos):\r\n",
    "    maxs_x = []\r\n",
    "    maxs_y = []\r\n",
    "    min_value = 5\r\n",
    "\r\n",
    "    for video_name in list_videos:\r\n",
    "        maxs_x_, means_x_, stds_x_, maxs_y_, means_y_, stds_y_ = np.array(\r\n",
    "            list(zip(*np.load(os.path.join(path_data, video_name, 'flow_values_mask.npy')))))\r\n",
    "        maxs_x.extend(maxs_x_)\r\n",
    "        maxs_y.extend(maxs_y_)\r\n",
    "    global mean_x, std_x, mean_y, std_y\r\n",
    "    maxs_x = np.array(maxs_x)\r\n",
    "    maxs_y = np.array(maxs_y)\r\n",
    "    mean_x = maxs_x[maxs_x > min_value].mean()\r\n",
    "    std_x = maxs_x[maxs_x > min_value].std()\r\n",
    "\r\n",
    "    mean_y = maxs_y[maxs_y > min_value].mean()\r\n",
    "    std_y = maxs_y[maxs_y > min_value].std()\r\n",
    "    print('Normalization value:\\n \\t mean_x: %.2f +- %.2f \\n \\t mean_y %.2f +- %.2f' %\r\n",
    "          (mean_x, std_x, mean_y, std_y))\r\n",
    "\r\n",
    "\r\n",
    "def normalize_optical_flow(flow):\r\n",
    "    global mean_x, std_x, mean_y, std_y\r\n",
    "    # Normal Normalization\r\n",
    "    flow_normed = np.dstack((flow[:, :, 0] / (mean_x + 3*std_x),\r\n",
    "                             flow[:, :, 1] / (mean_y + 3*std_y)))\r\n",
    "    flow_normed[flow_normed > 1] = 1\r\n",
    "    flow_normed[flow_normed < -1] = -1\r\n",
    "\r\n",
    "    return flow_normed\r\n",
    "\r\n",
    "\r\n",
    "def process_coordinates_pose(coord, zoom, R_matrix, flip, width, height, tx, ty, pose_norm_method='image_size'):\r\n",
    "    # y, x\r\n",
    "    v = [coord[0], coord[1], 1]\r\n",
    "\r\n",
    "    # # Grab  the rotation components of the matrix)\r\n",
    "    # cos = np.abs(R_matrix[0, 0])\r\n",
    "    # sin = np.abs(R_matrix[0, 1])\r\n",
    "    # # compute the new bounding dimensions of the image\r\n",
    "    # nW = int((height * sin) + (width * cos))\r\n",
    "    # nH = int((height * cos) + (width * sin))\r\n",
    "    # # adjust the rotation matrix to take into account translation\r\n",
    "    # R_matrix_coord = R_matrix.copy()\r\n",
    "    # R_matrix_coord[0, 2] += (nW / 2) - cx\r\n",
    "    # R_matrix_coord[1, 2] += (nH / 2) - cy\r\n",
    "\r\n",
    "    # Rotation of the coordinates\r\n",
    "    # v = np.dot(R_matrix_coord, v)\r\n",
    "    if R_matrix is not None:\r\n",
    "        v = np.dot(R_matrix, v)\r\n",
    "\r\n",
    "    new_coord = [zoom*(v[1]+tx), zoom*(v[0]+ty)]\r\n",
    "\r\n",
    "    if flip:\r\n",
    "        new_coord[0] = zoom*width - new_coord[0]\r\n",
    "\r\n",
    "    if pose_norm_method == 'image_size':\r\n",
    "        new_coord = [new_coord[0]/(width*zoom), new_coord[1]/(height*zoom)]\r\n",
    "\r\n",
    "    return new_coord\r\n",
    "\r\n",
    "###############################################################################\r\n",
    "################################# Get data ####################################\r\n",
    "###############################################################################\r\n",
    "\r\n",
    "\r\n",
    "def get_data(annotation, size_data, augmentation=0, path_to_save=None, pose_norm_method='image_size', model_type='TwinPose'):\r\n",
    "    # Variables\r\n",
    "    rgb_data = []\r\n",
    "    flow_data = []\r\n",
    "    pose_data = []\r\n",
    "\r\n",
    "    crop_Flow = os.path.join(annotation.video_name, 'roi_mask.npy')\r\n",
    "    path_RGB = os.path.join(annotation.video_name, 'rgb')\r\n",
    "    path_Mask = os.path.join(annotation.video_name, 'mask')\r\n",
    "    path_Pose = os.path.join(annotation.video_name, 'pose')\r\n",
    "    Pose_parts = ['nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\r\n",
    "                  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist', 'leftHip', 'rightHip']\r\n",
    "    path_Flow = os.path.join(annotation.video_name, 'flow')\r\n",
    "    x_list, y_list = np.asarray(np.load(crop_Flow)).astype(float)\r\n",
    "\r\n",
    "    rgb_example = cv2.imread(os.path.join(path_RGB, '%08d.png' % 0))\r\n",
    "    shape = rgb_example.shape\r\n",
    "\r\n",
    "    if path_to_save is not None:\r\n",
    "        # count = len([f for f in os.listdir(path_to_save) if os.path.isfile(os.path.join(path_to_save, f))])/4\r\n",
    "        path_to_save = os.path.join(\r\n",
    "            path_to_save, '%04d' % len(os.listdir(path_to_save)))\r\n",
    "        make_path(os.path.join(path_to_save))\r\n",
    "\r\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\r\n",
    "\r\n",
    "    # Smoothing of the crop center\r\n",
    "    x_list = cv2.GaussianBlur(x_list, (1, int(2 * 1./6 * 120 + 1)), 0)\r\n",
    "    y_list = cv2.GaussianBlur(y_list, (1, int(2 * 1./6 * 120 + 1)), 0)\r\n",
    "\r\n",
    "    # Random transformations parameters and begin of the interval according to the window\r\n",
    "    if augmentation:\r\n",
    "        angle, zoom, tx, ty, flip, begin = get_augmentation_parameters(\r\n",
    "            annotation, size_data)\r\n",
    "        angle_radian = math.radians(angle)\r\n",
    "    else:\r\n",
    "        tx = 0\r\n",
    "        ty = 0\r\n",
    "        flip = False\r\n",
    "        zoom = 1\r\n",
    "        angle = 0\r\n",
    "        begin = (annotation.begin + annotation.end + 1 - size_data[0]) // 2\r\n",
    "\r\n",
    "    begin = max(begin, 0)\r\n",
    "    for frame_number in range(begin, begin + size_data[0]):\r\n",
    "\r\n",
    "        x_seg = x_list[frame_number - 1][0]\r\n",
    "        y_seg = y_list[frame_number - 1][0]\r\n",
    "\r\n",
    "        if augmentation:\r\n",
    "            # Rotation Matrix\r\n",
    "            R_matrix = cv2.getRotationMatrix2D((x_seg, y_seg), angle, 1)\r\n",
    "        else:\r\n",
    "            R_matrix = None\r\n",
    "\r\n",
    "        #################\r\n",
    "        ###### Pose #####\r\n",
    "        #################\r\n",
    "        if 'Pose' in model_type:\r\n",
    "            pose = []\r\n",
    "            pose_list = np.load(os.path.join(\r\n",
    "                path_Pose, '%08d.npy' % (frame_number)))\r\n",
    "\r\n",
    "            # Take the best pose according to our ROI\r\n",
    "            if len(pose_list) == 0:\r\n",
    "                pose_dict = None\r\n",
    "            elif len(pose_list) == 1:\r\n",
    "                pose_dict = pose_list[0]\r\n",
    "            elif len(pose_list) > 1:\r\n",
    "                dist = []\r\n",
    "                for pose_dict in pose_list:\r\n",
    "                    score, coord = pose_dict['Scrore pose']\r\n",
    "                    dist.append(sum(abs(coord-np.array([y_seg, x_seg]))))\r\n",
    "                pose_dict = pose_list[np.array(dist).argmin()]\r\n",
    "\r\n",
    "            # For each part of the body, keep coordinates and score (default is our ROI)\r\n",
    "            if pose_dict is not None:\r\n",
    "\r\n",
    "                score, coord = pose_dict['Scrore pose']\r\n",
    "                coord_norm = process_coordinates_pose(\r\n",
    "                    coord, zoom, R_matrix, flip, 320, 180, tx, ty, pose_norm_method=pose_norm_method)\r\n",
    "                pose.extend([coord_norm[0], coord_norm[1], score])\r\n",
    "\r\n",
    "                for Pose_part in Pose_parts:\r\n",
    "                    if flip:\r\n",
    "                        if Pose_part[:4] == 'left':\r\n",
    "                            score, coord = pose_dict['right'+Pose_part[4:]]\r\n",
    "                        elif Pose_part[:5] == 'right':\r\n",
    "                            score, coord = pose_dict['left'+Pose_part[5:]]\r\n",
    "                        else:\r\n",
    "                            score, coord = pose_dict[Pose_part]\r\n",
    "                    else:\r\n",
    "                        score, coord = pose_dict[Pose_part]\r\n",
    "                    pose.extend([coord_norm[0], coord_norm[1], score])\r\n",
    "\r\n",
    "            else:\r\n",
    "                coord_norm = process_coordinates_pose(\r\n",
    "                    (x_seg, y_seg), zoom, R_matrix, flip, 320, 180, tx, ty, pose_norm_method=pose_norm_method)\r\n",
    "                for i in range(len(Pose_parts)+1):\r\n",
    "                    pose.extend([coord_norm[0], coord_norm[1], 0])\r\n",
    "\r\n",
    "            pose_data.append(pose)\r\n",
    "\r\n",
    "        # Update coordinates\r\n",
    "        if flip:\r\n",
    "            x_seg = shape[1] - x_seg\r\n",
    "\r\n",
    "        # Coordinates correction to fit in the image\r\n",
    "        x_seg, y_seg = correction_coordinates(\r\n",
    "            zoom * (x_seg + tx), zoom * (y_seg + ty), size_data[1:], shape)\r\n",
    "        x_seg = int(x_seg - size_data[2] * 0.5)\r\n",
    "        y_seg = int(y_seg - size_data[1] * 0.5)\r\n",
    "\r\n",
    "        #################\r\n",
    "        ###### Flow #####\r\n",
    "        #################\r\n",
    "        if ('Flow' in model_type) or ('Twin' in model_type):\r\n",
    "            try:\r\n",
    "                flow = np.load(os.path.join(\r\n",
    "                    path_Flow, '%08d.npy' % frame_number))\r\n",
    "            except:\r\n",
    "                raise ValueError('Problem with %s begin %d inter %d-%d step %d T %d' % (os.path.join(\r\n",
    "                    path_Flow, '%08d.npy' % frame_number), begin, annotation.begin, annotation.end, step, size_data[0]))\r\n",
    "\r\n",
    "            flow = cv2.GaussianBlur(flow, (3, 3), 0)\r\n",
    "            mask = cv2.imread(os.path.join(path_Mask, '%08d.png' %\r\n",
    "                                           frame_number), cv2.IMREAD_GRAYSCALE) / 255\r\n",
    "            mask = cv2.dilate(mask, kernel)\r\n",
    "            flow = np.multiply(flow, np.dstack((mask, mask)))\r\n",
    "            flow = normalize_optical_flow(flow)\r\n",
    "\r\n",
    "            if augmentation:\r\n",
    "                flow = apply_augmentation(\r\n",
    "                    flow, zoom, R_matrix, angle_radian, flip, flow_values=True)\r\n",
    "\r\n",
    "            flow_croped = flow[y_seg: y_seg +\r\n",
    "                               size_data[1], x_seg: x_seg + size_data[2]]\r\n",
    "            flow_data.append(flow_croped)\r\n",
    "\r\n",
    "        #################\r\n",
    "        ###### RGB ######\r\n",
    "        #################\r\n",
    "        if ('RGB' in model_type) or ('Twin' in model_type):\r\n",
    "            try:\r\n",
    "                rgb = cv2.imread(os.path.join(path_RGB, '%08d.png' %\r\n",
    "                                              frame_number)).astype(float) / 255\r\n",
    "            except:\r\n",
    "                raise ValueError('Problem with %s begin %d inter %d-%d step %d T %d' % (os.path.join(\r\n",
    "                    path_RGB, '%08d.png' % frame_number), begin, annotation.begin, annotation.end, step, size_data[0]))\r\n",
    "\r\n",
    "            if augmentation:\r\n",
    "                rgb = apply_augmentation(\r\n",
    "                    rgb, zoom, R_matrix, angle_radian, flip, flow_values=False)\r\n",
    "\r\n",
    "            rgb_croped = rgb[y_seg: y_seg + size_data[1],\r\n",
    "                             x_seg: x_seg + size_data[2]]\r\n",
    "            rgb_data.append(cv2.split(rgb_croped))\r\n",
    "\r\n",
    "    label = args.list_of_moves.index(annotation.move)\r\n",
    "\r\n",
    "    if 'Pose' in model_type:\r\n",
    "        pose_data = np.transpose(np.array(pose_data), (1, 0))\r\n",
    "\r\n",
    "    if ('RGB' in model_type) or ('Twin' in model_type):\r\n",
    "        rgb_data = np.transpose(rgb_data, (1, 0, 2, 3))\r\n",
    "\r\n",
    "    if ('Flow' in model_type) or ('Twin' in model_type):\r\n",
    "        flow_data = np.transpose(flow_data, (3, 0, 1, 2))\r\n",
    "\r\n",
    "    return rgb_data, flow_data, pose_data, label\r\n",
    "\r\n",
    "\r\n",
    "def correction_coordinates(x, y, size, shape):\r\n",
    "    diff = x - size[1] * 0.5\r\n",
    "    if diff < 0:\r\n",
    "        x = size[1] * 0.5\r\n",
    "\r\n",
    "    diff = x + size[1] * 0.5 - shape[1]\r\n",
    "    if diff > 0:\r\n",
    "        x = shape[1] - size[1] * 0.5\r\n",
    "\r\n",
    "    diff = y - size[0] * 0.5\r\n",
    "    if diff < 0:\r\n",
    "        y = size[0] * 0.5\r\n",
    "\r\n",
    "    diff = y + size[0] * 0.5 - shape[0]\r\n",
    "    if diff > 0:\r\n",
    "        y = shape[0] - size[0] * 0.5\r\n",
    "    return int(x), int(y)\r\n",
    "\r\n",
    "############################ Augmentation ####################################\r\n",
    "\r\n",
    "\r\n",
    "def get_augmentation_parameters(annotation, size_data, step=1):\r\n",
    "    angle = (random.random() * 2 - 1) * 10\r\n",
    "    zoom = 1 + (random.random() * 2 - 1) * 0.1\r\n",
    "\r\n",
    "    tx = random.randint(-0.1 * size_data[2], 0.1 * size_data[2])\r\n",
    "    ty = random.randint(-0.1 * size_data[1], 0.1 * size_data[1])\r\n",
    "\r\n",
    "    flip = random.randint(0, 1)\r\n",
    "\r\n",
    "    # Normal distribution to pick whre to begin #\r\n",
    "    mu = annotation.begin + (annotation.end + 1 -\r\n",
    "                             annotation.begin - step*size_data[0])/2\r\n",
    "    sigma = (annotation.end + 1 - annotation.begin - step*size_data[0])/6\r\n",
    "    begin = -1\r\n",
    "\r\n",
    "    if sigma <= 0:\r\n",
    "        begin = max(int(mu), 0)\r\n",
    "    else:\r\n",
    "        count = 0\r\n",
    "        while not annotation.begin <= begin <= annotation.end + 1 - step*size_data[0]:\r\n",
    "            begin = int(np.random.normal(mu, sigma))\r\n",
    "            count += 1\r\n",
    "            if count > 10:\r\n",
    "                print('Warning: augmentation with picking frame has a problem')\r\n",
    "\r\n",
    "    return angle, zoom, tx, ty, flip, begin\r\n",
    "\r\n",
    "\r\n",
    "def apply_augmentation(data, zoom, R_matrix, angle_radian, flip, flow_values=False):\r\n",
    "    if data is not None:\r\n",
    "        # Resize and Rotation\r\n",
    "        shape = data.shape\r\n",
    "        data = cv2.resize(cv2.warpAffine(\r\n",
    "            data, R_matrix, (shape[1], shape[0])), (0, 0), fx=zoom, fy=zoom)\r\n",
    "        if flow_values:\r\n",
    "            data *= zoom\r\n",
    "\r\n",
    "            # Update Flow values according to rotation\r\n",
    "            tmp = cv2.addWeighted(data[:, :, 0], math.cos(\r\n",
    "                angle_radian), data[:, :, 1], -math.sin(angle_radian), 0)\r\n",
    "            data[:, :, 1] = cv2.addWeighted(data[:, :, 0], math.sin(\r\n",
    "                angle_radian), data[:, :, 1], math.cos(angle_radian), 0)\r\n",
    "            data[:, :, 0] = tmp\r\n",
    "\r\n",
    "        # Flip\r\n",
    "        if flip:\r\n",
    "            data = cv2.flip(data, 1)\r\n",
    "            if flow_values:\r\n",
    "                data = -data\r\n",
    "    return data\r\n",
    "\r\n",
    "####################################################################\r\n",
    "######################### Dataset Class ############################\r\n",
    "####################################################################\r\n",
    "\r\n",
    "\r\n",
    "class My_dataset(Dataset):\r\n",
    "    def __init__(self, dataset_list, size_data, augmentation=0, model_type='TwinPose'):\r\n",
    "        self.dataset_list = dataset_list\r\n",
    "        self.size_data = size_data\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.model_type = model_type\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.dataset_list)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        rgb, flow, pose, label = get_data(\r\n",
    "            self.dataset_list[idx], self.size_data, self.augmentation, model_type=self.model_type)\r\n",
    "        sample = {'rgb': torch.FloatTensor(rgb), 'flow': torch.FloatTensor(flow), 'pose': torch.FloatTensor(pose), 'label': label, 'my_stroke': {\r\n",
    "            'video_name': self.dataset_list[idx].video_name, 'begin': self.dataset_list[idx].begin, 'end': self.dataset_list[idx].end}}\r\n",
    "        return sample\r\n",
    "\r\n",
    "\r\n",
    "class My_test_dataset(Dataset):\r\n",
    "    def __init__(self, interval, size_data, augmentation=0, model_type='TwinPose'):\r\n",
    "        self.interval = interval\r\n",
    "        middle = (interval.begin + interval.end + 1 - size_data[2]) // 2\r\n",
    "        n = max(0, (middle - interval.begin))\r\n",
    "        self.begin = middle - n\r\n",
    "        self.number_of_iteration = n * 2 + 1\r\n",
    "        self.size_data = size_data\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.model_type = model_type\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.number_of_iteration\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        begin = self.begin + idx\r\n",
    "        windowed_interval = MyStroke(\r\n",
    "            self.interval.video_name, begin, begin + self.size_data[2], self.interval.move)\r\n",
    "        rgb, flow, pose, label = get_data(\r\n",
    "            windowed_interval, self.size_data, self.augmentation, model_type=self.model_type)\r\n",
    "        sample = {'rgb': torch.FloatTensor(rgb), 'flow': torch.FloatTensor(flow), 'pose': torch.FloatTensor(pose), 'label': label, 'my_stroke': {\r\n",
    "            'video_name': self.interval.video_name, 'begin': self.interval.begin, 'end': self.interval.end}}\r\n",
    "        return sample\r\n",
    "\r\n",
    "    def my_print(self, show_option=1):\r\n",
    "        self.interval.my_print()\r\n",
    "        # save_my_dataset(self.annotation, augmentation = self.augmentation, show_option = show_option)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "######################## Save and Load Model #############################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "def save_model(model, args, optimizer, epoch, dict_of_values):\r\n",
    "    torch.save({'epoch': epoch,\r\n",
    "                'model_state_dict': model.state_dict(),\r\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\r\n",
    "                'dict_of_values': dict_of_values,\r\n",
    "                'args': args.state_dict()}, os.path.join(args.path_fig_model, 'model.tar'))\r\n",
    "\r\n",
    "\r\n",
    "def load_model(model, weigth_path, optimizer=None):\r\n",
    "    checkpoint = torch.load(os.path.join(\r\n",
    "        weigth_path, 'model.tar'), map_location=lambda storage, loc: storage)\r\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\r\n",
    "    epoch = checkpoint['epoch']\r\n",
    "    dict_of_values = checkpoint['dict_of_values']\r\n",
    "    args_dict = checkpoint['args']\r\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
    "    return epoch, dict_of_values, args_dict\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "########################### Training Process #############################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "def train_epoch(epoch, args, model, data_loader, optimizer, criterion):\r\n",
    "    model.train()\r\n",
    "    N = len(data_loader.dataset)\r\n",
    "    start_time = time.time()\r\n",
    "    aLoss = 0\r\n",
    "    Acc = 0\r\n",
    "\r\n",
    "    for batch_idx, batch in enumerate(data_loader):\r\n",
    "        # Get batch tensor\r\n",
    "        rgb, flow, label = batch['rgb'], batch['flow'], batch['label']\r\n",
    "\r\n",
    "        rgb = Variable(rgb.type(args.dtype))\r\n",
    "        flow = Variable(flow.type(args.dtype))\r\n",
    "        label = Variable(label.type(args.dtype).long())\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(rgb, flow)\r\n",
    "        loss = criterion(output, label)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        aLoss += loss.item()\r\n",
    "        Acc += output.data.max(1)[1].eq(label.data).cpu().sum().numpy()\r\n",
    "\r\n",
    "    aLoss /= (batch_idx + 1)\r\n",
    "    return aLoss, Acc/N\r\n",
    "\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "######################## Validation Process ##############################\r\n",
    "##########################################################################\r\n",
    "def validation_epoch(epoch, args, model, data_loader, criterion):\r\n",
    "    with torch.no_grad():\r\n",
    "        N = len(data_loader.dataset)\r\n",
    "        aLoss = 0\r\n",
    "        Acc = 0\r\n",
    "\r\n",
    "        for batch_idx, batch in enumerate(data_loader):\r\n",
    "            # Get batch tensor\r\n",
    "            rgb, flow, label = batch['rgb'], batch['flow'], batch['label']\r\n",
    "\r\n",
    "            rgb = Variable(rgb.type(args.dtype))\r\n",
    "            flow = Variable(flow.type(args.dtype))\r\n",
    "            label = Variable(label.type(args.dtype).long())\r\n",
    "\r\n",
    "            output = model(rgb, flow)\r\n",
    "\r\n",
    "            aLoss += criterion(output, label).item()\r\n",
    "            Acc += output.data.max(1)[1].eq(label.data).cpu().sum().numpy()\r\n",
    "\r\n",
    "            progress_bar((batch_idx + 1) * args.batch_size,\r\n",
    "                         N, '%d - Validation' % (pid))\r\n",
    "\r\n",
    "        aLoss /= (batch_idx + 1)\r\n",
    "\r\n",
    "        return aLoss, Acc/N\r\n",
    "\r\n",
    "##########################################################################\r\n",
    "############################# TRAINING ###################################\r\n",
    "##########################################################################\r\n",
    "\r\n",
    "\r\n",
    "def train_model(model, args, train_loader, validation_loader):\r\n",
    "    criterion = nn.CrossEntropyLoss()  # change with reduction='sum' -> lr to change\r\n",
    "    optimizer = optim.SGD(model.parameters(\r\n",
    "    ), lr=args.lr, momentum=args.momentum, weight_decay=args.decay, nesterov=args.nesterov)\r\n",
    "\r\n",
    "    # For plot\r\n",
    "    loss_train = []\r\n",
    "    loss_val = []\r\n",
    "    acc_val = []\r\n",
    "    acc_train = []\r\n",
    "    max_acc = -1\r\n",
    "    acc_val_ = 1\r\n",
    "    min_loss_train = 1000\r\n",
    "    min_loss_val = 1000\r\n",
    "\r\n",
    "    if args.load:\r\n",
    "        print_and_log('Load previous model for retraining', log=args.log)\r\n",
    "        epoch, dict_of_values, _ = load_model(\r\n",
    "            model, args.path_fig_model, optimizer=optimizer)\r\n",
    "        print_and_log('Model from epoch %d' % (epoch), log=args.log)\r\n",
    "        max_acc = dict_of_values['acc_val_']\r\n",
    "        min_loss_val = dict_of_values['loss_val_']\r\n",
    "        for key in dict_of_values:\r\n",
    "            print_and_log('%s : %g' % (key, dict_of_values[key]), log=args.log)\r\n",
    "        change_optimizer(optimizer, args, lr=args.lr_max)\r\n",
    "\r\n",
    "    for epoch in range(1, args.epochs+1):\r\n",
    "\r\n",
    "        # Train and validation step and save loss and acc for plot\r\n",
    "        loss_train_, acc_train_ = train_epoch(\r\n",
    "            epoch, args, model, train_loader, optimizer, criterion)\r\n",
    "        loss_val_, acc_val_ = validation_epoch(\r\n",
    "            epoch, args, model, validation_loader, criterion)\r\n",
    "\r\n",
    "        loss_train.append(loss_train_)\r\n",
    "        acc_train.append(acc_train_)\r\n",
    "        loss_val.append(loss_val_)\r\n",
    "        acc_val.append(acc_val_)\r\n",
    "\r\n",
    "        wait_change_lr += 1\r\n",
    "\r\n",
    "        # Best model saved\r\n",
    "        # if (acc_val_ > max_acc) or (acc_val_ >= max_acc and loss_train_ < min_loss_train):\r\n",
    "        if min_loss_val > loss_val_:\r\n",
    "            save_model(model, args, optimizer=optimizer, epoch=epoch, dict_of_values={\r\n",
    "                       'loss_train_': loss_train_, 'acc_train_': acc_train_, 'loss_val_': loss_val_, 'acc_val_': acc_val_})\r\n",
    "            max_acc = acc_val_\r\n",
    "            min_loss_val = loss_val_\r\n",
    "            min_loss_train = loss_train_\r\n",
    "\r\n",
    "    print_and_log('Trained with %d epochs, lr = %g, batchsize = %d, momentum = %g with max validation accuracy of %.2f done in %ds' %\r\n",
    "                  (args.epochs, args.lr, args.batch_size, args.momentum, max_acc, time.time() - start_time), log=args.log)\r\n",
    "\r\n",
    "    make_train_figure(loss_train, loss_val, acc_val, acc_train,\r\n",
    "                      os.path.join(args.path_fig_model, 'Train.png'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "##########################################################################\r\n",
    "############# Batch Normalization 1D for ND tensors  #####################\r\n",
    "##########################################################################\r\n",
    "class MyBatchNorm(_BatchNorm):  # Replace nn.BatchNorm3d\r\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True):\r\n",
    "        super(MyBatchNorm, self).__init__(num_features,\r\n",
    "                                          eps, momentum, affine, track_running_stats)\r\n",
    "\r\n",
    "    def _check_input_dim(self, input):\r\n",
    "        self.saved_shape = input.shape\r\n",
    "        if input.dim() != 2 and input.dim() != 3:\r\n",
    "            return input.reshape((input.shape[0], input.shape[1], input[0, 0].numel()))\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        input = self._check_input_dim(input)\r\n",
    "        # exponential_average_factor is set to self.momentum\r\n",
    "        # (when it is available) only so that if gets updated\r\n",
    "        # in ONNX graph when this node is exported to ONNX.\r\n",
    "        if self.momentum is None:\r\n",
    "            exponential_average_factor = 0.0\r\n",
    "        else:\r\n",
    "            exponential_average_factor = self.momentum\r\n",
    "\r\n",
    "        if self.training and self.track_running_stats:\r\n",
    "            # TODO: if statement only here to tell the jit to skip emitting this when it is None\r\n",
    "            if self.num_batches_tracked is not None:\r\n",
    "                self.num_batches_tracked = self.num_batches_tracked + 1\r\n",
    "                if self.momentum is None:  # use cumulative moving average\r\n",
    "                    exponential_average_factor = 1.0 / \\\r\n",
    "                        float(self.num_batches_tracked)\r\n",
    "                else:  # use exponential moving average\r\n",
    "                    exponential_average_factor = self.momentum\r\n",
    "\r\n",
    "        output = F.batch_norm(input, self.running_mean, self.running_var, self.weight, self.bias,\r\n",
    "                              self.training or not self.track_running_stats, exponential_average_factor, self.eps)\r\n",
    "\r\n",
    "        output = output.reshape(self.saved_shape)\r\n",
    "\r\n",
    "        return output\r\n",
    "\r\n",
    "\r\n",
    "###################################################################\r\n",
    "####################### 3D Attention Model  #######################\r\n",
    "###################################################################\r\n",
    "class ResidualBlock3D(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, stride=1):\r\n",
    "        super(ResidualBlock3D, self).__init__()\r\n",
    "\r\n",
    "        dim_conv = math.ceil(out_dim/4)\r\n",
    "\r\n",
    "        self.in_dim = in_dim\r\n",
    "        self.out_dim = out_dim\r\n",
    "        self.stride = stride\r\n",
    "        self.bn1 = MyBatchNorm(in_dim)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.conv1 = nn.Conv3d(in_dim, dim_conv, 1, 1, bias=False)\r\n",
    "        self.bn2 = MyBatchNorm(dim_conv)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.conv2 = nn.Conv3d(dim_conv, dim_conv, 3,\r\n",
    "                               stride, padding=1, bias=False)\r\n",
    "        self.bn3 = MyBatchNorm(dim_conv)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.conv3 = nn.Conv3d(dim_conv, out_dim, 1, 1, bias=False)\r\n",
    "        if (self.in_dim != self.out_dim) or (self.stride != 1):\r\n",
    "            self.conv4 = nn.Conv3d(in_dim, out_dim, 1, stride, bias=False)\r\n",
    "\r\n",
    "        ## Use GPU\r\n",
    "        if param.cuda:\r\n",
    "            self.cuda()\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        residual = input\r\n",
    "        out = self.bn1(input)\r\n",
    "        out1 = self.relu(out)\r\n",
    "        out = self.conv1(out1)\r\n",
    "        out = self.bn2(out)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.conv2(out)\r\n",
    "        out = self.bn3(out)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.conv3(out)\r\n",
    "        if (self.in_dim != self.out_dim) or (self.stride != 1):\r\n",
    "            residual = self.conv4(out1)\r\n",
    "        out += residual\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class AttentionModule3D(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, size1, size2, size3):\r\n",
    "        super(AttentionModule3D, self).__init__()\r\n",
    "\r\n",
    "        self.size1 = tuple(size1.astype(int))\r\n",
    "        self.size2 = tuple(size2.astype(int))\r\n",
    "        self.size3 = tuple(size3.astype(int))\r\n",
    "\r\n",
    "        self.first_residual_blocks = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.trunk_branches = nn.Sequential(\r\n",
    "            ResidualBlock3D(in_dim, out_dim),\r\n",
    "            ResidualBlock3D(in_dim, out_dim)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        self.block1 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.skip1 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        self.block2 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.skip2 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        self.block3 = nn.Sequential(\r\n",
    "            ResidualBlock3D(in_dim, out_dim),\r\n",
    "            ResidualBlock3D(in_dim, out_dim)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.block4 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.block5 = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        self.block6 = nn.Sequential(\r\n",
    "            MyBatchNorm(out_dim),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv3d(out_dim, out_dim, kernel_size=1, stride=1, bias=False),\r\n",
    "            MyBatchNorm(out_dim),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv3d(out_dim, out_dim, kernel_size=1, stride=1, bias=False),\r\n",
    "            nn.Sigmoid()\r\n",
    "        )\r\n",
    "\r\n",
    "        self.final = ResidualBlock3D(in_dim, out_dim)\r\n",
    "\r\n",
    "        ## Use GPU\r\n",
    "        if param.cuda:\r\n",
    "            self.cuda()\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        input = self.first_residual_blocks(input)\r\n",
    "        out_trunk = self.trunk_branches(input)\r\n",
    "\r\n",
    "        # 1st level\r\n",
    "        out_pool1 = self.pool1(input)\r\n",
    "        out_block1 = self.block1(out_pool1)\r\n",
    "        out_skip1 = self.skip1(out_block1)\r\n",
    "\r\n",
    "        #2sd level\r\n",
    "        out_pool2 = self.pool2(out_block1)\r\n",
    "        out_block2 = self.block2(out_pool2)\r\n",
    "        out_skip2 = self.skip2(out_block2)\r\n",
    "\r\n",
    "        # 3rd level\r\n",
    "        out_pool3 = self.pool3(out_block2)\r\n",
    "        out_block3 = self.block3(out_pool3)\r\n",
    "        out_interp3 = F.interpolate(\r\n",
    "            out_block3, size=self.size3, mode='trilinear', align_corners=True)\r\n",
    "        out = out_interp3 + out_skip2\r\n",
    "\r\n",
    "        #4th level\r\n",
    "        out_softmax4 = self.block4(out)\r\n",
    "        out_interp2 = F.interpolate(\r\n",
    "            out_softmax4, size=self.size2, mode='trilinear', align_corners=True)\r\n",
    "        out = out_interp2 + out_skip1\r\n",
    "\r\n",
    "        #5th level\r\n",
    "        out_block5 = self.block5(out)\r\n",
    "        out_interp1 = F.interpolate(\r\n",
    "            out_block5, size=self.size1, mode='trilinear', align_corners=True)\r\n",
    "\r\n",
    "        #6th level\r\n",
    "        out_block6 = self.block6(out_interp1)\r\n",
    "        out = (1 + out_block6) * out_trunk\r\n",
    "\r\n",
    "        # Final with Attention added\r\n",
    "        out_last = self.final(out)\r\n",
    "\r\n",
    "        return out_last\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name '_BatchNorm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2d466c560084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m############# Batch Normalization 1D for ND tensors  #####################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m##########################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mMyBatchNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BatchNorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Replace nn.BatchNorm3d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         super(MyBatchNorm, self).__init__(num_features,\n",
      "\u001b[1;31mNameError\u001b[0m: name '_BatchNorm' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('dlapp': conda)"
  },
  "interpreter": {
   "hash": "f669473434b0c71a08312914e81c73b2c7471a3c7bfd138db5a6bbb55bcafdbb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}